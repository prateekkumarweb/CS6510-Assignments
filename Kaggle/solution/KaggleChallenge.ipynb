{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictonaries that will be used to convert categorical data to integers\n",
    "\n",
    "job_dict = {'admin.':0,'blue-collar':1,'entrepreneur':2,'housemaid':3,'management':4,'retired':5,'self-employed':6,'services':7,'student':8,'technician':9,'unemployed':10,'unknown':11}\n",
    "mar_dict = {'divorced':0,'married':1,'single':2,'unknown':3}\n",
    "edu_dict = {'basic.4y':0,'basic.6y':1,'basic.9y':2,'high.school':3,'illiterate':4,'professional.course':5,'university.degree':6,'unknown':7}\n",
    "nyu_dict = {'no':0,'unknown':1,'yes':2}\n",
    "con_dict = {'cellular':0,'telephone':1}\n",
    "mon_dict = {'jan':0,'feb':1,'mar':2,'apr':3,'may':4,'jun':5,'jul':6,'aug':7,'sep':8,'oct':9,'nov':10,'dec':11}\n",
    "dow_dict = {'mon':0,'tue':1,'wed':2,'thu':3,'fri':4}\n",
    "poc_dict = {'failure':0,'nonexistent':1,'success':2}\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Sanitize the data\n",
    "def sanitize(dataset) :\n",
    "    n = len(dataset)\n",
    "    data = np.empty((n, len(dataset[0])), dtype=np.float64)\n",
    "    # Convert data to float which are numeric\n",
    "    data[:,0] = dataset[:,0].astype(np.float64)\n",
    "    data[:,10] = dataset[:,10].astype(np.float64)\n",
    "    data[:,11] = dataset[:,11].astype(np.float64)\n",
    "    data[:,12] = dataset[:,12].astype(np.float64)\n",
    "    data[:,14] = dataset[:,14].astype(np.float64)\n",
    "    data[:,15] = dataset[:,15].astype(np.float64)\n",
    "    data[:,16] = dataset[:,16].astype(np.float64)\n",
    "    data[:,17] = dataset[:,17].astype(np.float64)\n",
    "    data[:,18] = dataset[:,18].astype(np.float64)\n",
    "    # If input has class labels then convert them too\n",
    "    if (len(dataset[0]) == 20) :\n",
    "        data[:,19] = dataset[:,19].astype(np.float64)\n",
    "    # Replace categoricals data with their corresponding numeric values from dictionaries\n",
    "    for i in xrange(n):\n",
    "        data[i,1] = job_dict[dataset[i,1][1:-1]]\n",
    "        data[i,2] = mar_dict[dataset[i,2][1:-1]]\n",
    "        data[i,3] = edu_dict[dataset[i,3][1:-1]]\n",
    "        data[i,4] = nyu_dict[dataset[i,4][1:-1]]\n",
    "        data[i,5] = nyu_dict[dataset[i,5][1:-1]]\n",
    "        data[i,6] = nyu_dict[dataset[i,6][1:-1]]\n",
    "        data[i,7] = con_dict[dataset[i,7][1:-1]]\n",
    "        data[i,8] = mon_dict[dataset[i,8][1:-1]]\n",
    "        data[i,9] = dow_dict[dataset[i,9][1:-1]]\n",
    "        data[i,13] = poc_dict[dataset[i,13][1:-1]]\n",
    "    return data\n",
    "\n",
    "# Initialize dataset from csv files\n",
    "dataset = np.genfromtxt(\"trainData.csv\", delimiter=',', dtype=\"|S50\", autostrip=True)\n",
    "dataset = dataset[1:]\n",
    "\n",
    "# Seperate the dataset based on classlabels\n",
    "dataset_0 = dataset[dataset[:,-1] == '0']\n",
    "dataset_1 = dataset[dataset[:,-1] == '1']\n",
    "\n",
    "# Split the dataset into train and validation set\n",
    "trainset = np.concatenate((dataset_0[:4*len(dataset_0)//5], dataset_1[:4*len(dataset_1)//5]), axis=0)\n",
    "validationset = np.concatenate((dataset_0[4*len(dataset_0)//5:], dataset_1[4*len(dataset_1)//5:]), axis=0)\n",
    "\n",
    "# Sanitize the dataset\n",
    "data = sanitize(dataset)\n",
    "train = sanitize(trainset)\n",
    "valid = sanitize(validationset)\n",
    "\n",
    "# Validation set, sepaerate features and class labels\n",
    "valid_f = valid[:,:-1]\n",
    "valid_v = valid[:,-1].astype(np.int)\n",
    "\n",
    "# Load testset and sanitize it\n",
    "testset = np.genfromtxt(\"testData.csv\",delimiter=',',dtype=\"|S50\",autostrip=True)\n",
    "testset = testset[1:]\n",
    "testset = testset[:,1:]\n",
    "test = sanitize(testset)\n",
    "\n",
    "# Train classifier clf\n",
    "def train_clf(clf):\n",
    "    # Fit train set\n",
    "    clf.fit(train[:,:-1],train[:,-1].astype(np.int))\n",
    "    # Predict on validation set\n",
    "    valid_p = clf.predict_proba(valid_f)\n",
    "    # Calculate and print the roc auc score\n",
    "    result = valid_p[:,1]\n",
    "    print roc_auc_score(valid_v, result)\n",
    "\n",
    "# Test classifier clf and print output to file\n",
    "def test_clf(clf, file):\n",
    "    # Fit the whole dataset\n",
    "    clf.fit(data[:,:-1],data[:,-1].astype(np.int))\n",
    "    # Predict on the test set\n",
    "    test_p = clf.predict_proba(test)\n",
    "    test_f = np.empty((len(test), 2), dtype=np.float)\n",
    "    for i in xrange(len(test)) :\n",
    "        test_f[i,0] = i+1\n",
    "        test_f[i,1] = test_p[i,1]\n",
    "    # Write output to file\n",
    "    with open(file, 'wb') as f :\n",
    "        f.write(b'Id,Class\\n')\n",
    "        np.savetxt(f,test_f,'%d,%f',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.799823332114\n"
     ]
    }
   ],
   "source": [
    "# Submission 1\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf1 = GradientBoostingClassifier(random_state=18,max_depth=7,n_estimators=100,min_samples_split=150)\n",
    "train_clf(clf1)\n",
    "test_clf(clf1, 'sub1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.799305935894\n"
     ]
    }
   ],
   "source": [
    "# Submission 2\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf2 = RandomForestClassifier(criterion='entropy',max_depth=12,class_weight='balanced',min_samples_split=150,n_estimators=200,random_state=18)\n",
    "train_clf(clf2)\n",
    "test_clf(clf2, 'sub2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissions\n",
    "\n",
    "I have done no normalizations (because doing made my score worse), converted all data to float. I have seperated dataset into train set and validation set to get an estimate of roc auc score. I have trained again on whole dataset for predicting on test set.\n",
    "\n",
    "The classifiers used for various submissions and their corresponding roc auc scores are given below. Submissions 1 and 2 are used for calcuating scores in private leaderboard.\n",
    "\n",
    "Submission 1 : 0.799823332114\n",
    "```py\n",
    "clf = GradientBoostingClassifier(random_state=18,max_depth=7,n_estimators=100,min_samples_split=150)\n",
    "```\n",
    "Submission 2 : 0.799305935894\n",
    "```py\n",
    "clf = RandomForestClassifier(criterion='entropy',max_depth=12,class_weight='balanced',min_samples_split=150,n_estimators=200,random_state=18)\n",
    "```\n",
    "Submission 3 : 0.792994029477\n",
    "```py\n",
    "clf = ExtraTreesClassifier(random_state=18,criterion='entropy',max_depth=15,n_estimators=250,min_samples_split=100,class_weight='balanced')\n",
    "```\n",
    "Submission 4 : 0.77123309764\n",
    "```py\n",
    "clf = RandomForestClassifier(criterion='entropy',max_depth=5,class_weight='balanced',min_samples_split=0.25,n_estimators=200,oob_score=True,random_state=18)\n",
    "```\n",
    "Submission 5 : 0.800019811691\n",
    "```py\n",
    "clf = GradientBoostingClassifier(random_state=18,max_depth=7,n_estimators=100,min_samples_split=0.2,min_samples_leaf=0.01)\n",
    "```\n",
    "Submission 6 : 0.803128077668\n",
    "```py\n",
    "clf = GradientBoostingClassifier(random_state=18,max_depth=9,n_estimators=150,min_samples_split=0.1,min_samples_leaf=0.01)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
